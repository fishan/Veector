{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw9ySaSDC5ItzU190z8NeH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fishan/Veector/blob/main/onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7ZrJZyRgazC"
      },
      "outputs": [],
      "source": [
        "!pip install onnx onnxruntime gdown transformers psutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import os\n",
        "import numpy as np\n",
        "import logging\n",
        "import zipfile\n",
        "import psutil\n",
        "import onnxruntime as ort\n",
        "from google.colab import drive\n",
        "from transformers import AutoTokenizer\n",
        "from onnx.external_data_helper import load_external_data_for_model\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "UZyO4ct4nLAM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
        "logging.basicConfig(level=logging.INFO, format=\"üü¢ [LOG] %(asctime)s - %(message)s\")\n",
        "logger = logging.getLogger()"
      ],
      "metadata": {
        "id": "5BP8KbQY6UGw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face (—á–µ—Ä–µ–∑ huggingface_hub)\n",
        "model_repo = \"onnx-community/DeepSeek-R1-Distill-Qwen-1.5B-ONNX\"\n",
        "model_filename = \"onnx/model_q4f16.onnx\"\n",
        "model_path = hf_hub_download(repo_id=model_repo, filename=model_filename)\n",
        "logger.info(f\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {model_path}\")"
      ],
      "metadata": {
        "id": "Z-pOwfKL6U7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º ONNX –º–æ–¥–µ–ª—å\n",
        "model = onnx.load(model_path)\n",
        "\n",
        "# üîπ –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ 1 –ú–ë\n",
        "chunk_size = 1024 * 1024 * 50  # 1 –ú–ë\n",
        "split_model_path = \"model_split.onnx\"\n",
        "onnx.save_model(model, split_model_path, save_as_external_data=True, all_tensors_to_one_file=False, size_threshold=chunk_size)\n",
        "\n",
        "# üîπ –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤\n",
        "files = [f for f in os.listdir() if f.startswith(\"model_split\")]\n",
        "logger.info(f\"üìÇ –†–∞–∑–±–∏—Ç—ã–µ —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–∏: {files}\")"
      ],
      "metadata": {
        "id": "uS2GSZUD6YQ2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≤ ONNX Runtime\n",
        "os.environ[\"ONNX_LOAD_EXTERNAL_LOGGING\"] = \"1\"\n",
        "onnx_model = onnx.load(split_model_path)\n",
        "session = ort.InferenceSession(split_model_path)\n",
        "logger.info(\"‚úÖ ONNX Runtime –∑–∞–≥—Ä—É–∂–µ–Ω.\")\n",
        "\n",
        "#--------------------------------------------------"
      ],
      "metadata": {
        "id": "YAykZU1A6jM8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –õ–æ–≥–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å\n",
        "memory_info = psutil.virtual_memory()\n",
        "logger.info(f\"üìä –ü–∞–º—è—Ç—å: {memory_info.used / (1024 * 1024):.2f} MB / {memory_info.total / (1024 * 1024):.2f} MB\")\n"
      ],
      "metadata": {
        "id": "89ypCidB6ra8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-1.8B-Chat\")"
      ],
      "metadata": {
        "id": "sKDaCsis6u3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
        "num_hidden_layers = 28\n",
        "num_key_value_heads = 2\n",
        "hidden_size = 1536\n",
        "head_dim = 128\n",
        "max_length = 128\n",
        "max_new_tokens = 512"
      ],
      "metadata": {
        "id": "0sfXYNvO63Sw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –§—É–Ω–∫—Ü–∏—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
        "def preprocess_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"np\", padding=False, truncation=True, max_length=max_length)\n",
        "    input_feed = {\n",
        "        \"input_ids\": inputs[\"input_ids\"].astype(np.int64),\n",
        "        \"attention_mask\": inputs[\"attention_mask\"].astype(np.int64),\n",
        "        \"position_ids\": np.arange(0, inputs[\"input_ids\"].shape[1], dtype=np.int64).reshape(1, -1),\n",
        "    }\n",
        "    batch_size = 1\n",
        "    for i in range(num_hidden_layers):\n",
        "        input_feed[f\"past_key_values.{i}.key\"] = np.zeros(\n",
        "            (batch_size, num_key_value_heads, 0, head_dim), dtype=np.float16\n",
        "        )\n",
        "        input_feed[f\"past_key_values.{i}.value\"] = np.zeros(\n",
        "            (batch_size, num_key_value_heads, 0, head_dim), dtype=np.float16\n",
        "        )\n",
        "    return input_feed, inputs[\"input_ids\"], inputs[\"attention_mask\"]\n"
      ],
      "metadata": {
        "id": "PEsizdCp7E71"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞\n",
        "def generate_text(input_feed, input_ids, attention_mask, max_new_tokens):\n",
        "    generated_ids = input_ids[0].tolist()  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –∏–∑ 2D –º–∞—Å—Å–∏–≤–∞\n",
        "    past_key_values = {k: v for k, v in input_feed.items() if \"past_key_values\" in k}\n",
        "\n",
        "    # –ü–µ—Ä–≤—ã–π —à–∞–≥\n",
        "    outputs = session.run(None, input_feed)\n",
        "    next_token = int(np.argmax(outputs[0][:, -1, :], axis=-1)[0])\n",
        "    generated_ids.append(next_token)\n",
        "\n",
        "    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ past_key_values\n",
        "    for i in range(num_hidden_layers):\n",
        "        past_key_values[f\"past_key_values.{i}.key\"] = outputs[2 * i + 1]\n",
        "        past_key_values[f\"past_key_values.{i}.value\"] = outputs[2 * i + 2]\n",
        "\n",
        "    # –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\n",
        "    for _ in range(max_new_tokens - 1):\n",
        "        input_feed = {\n",
        "            \"input_ids\": np.array([[next_token]], dtype=np.int64),  # 2D –º–∞—Å—Å–∏–≤\n",
        "            \"attention_mask\": np.array([[1]], dtype=np.int64),\n",
        "            \"position_ids\": np.array([[len(generated_ids) - 1]], dtype=np.int64),\n",
        "        }\n",
        "        input_feed.update(past_key_values)\n",
        "\n",
        "        outputs = session.run(None, input_feed)\n",
        "        next_token = int(np.argmax(outputs[0][:, -1, :], axis=-1)[0])\n",
        "        generated_ids.append(next_token)\n",
        "\n",
        "        for i in range(num_hidden_layers):\n",
        "            past_key_values[f\"past_key_values.{i}.key\"] = outputs[2 * i + 1]\n",
        "            past_key_values[f\"past_key_values.{i}.value\"] = outputs[2 * i + 2]\n",
        "\n",
        "        if next_token == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    return tokenizer.decode(generated_ids, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "qXVvF0ZJ7LNL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –§—É–Ω–∫—Ü–∏—è —á–∞—Ç–∞\n",
        "# –§—É–Ω–∫—Ü–∏—è —á–∞—Ç–∞\n",
        "def chat():\n",
        "    print(\"\\nü§ñ ONNX-–ß–∞—Ç –∞–∫—Ç–∏–≤–µ–Ω! –ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å ('–≤—ã—Ö–æ–¥' –¥–ª—è –≤—ã—Ö–æ–¥–∞).\")\n",
        "    while True:\n",
        "        user_input = input(\"–¢—ã: \")\n",
        "        if user_input.lower() == \"–≤—ã—Ö–æ–¥\":\n",
        "            print(\"ü§ñ –ß–∞—Ç –∑–∞–≤–µ—Ä—à–µ–Ω.\")\n",
        "            break\n",
        "\n",
        "        logger.info(\"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∑–∞–ø—Ä–æ—Å–∞...\")\n",
        "        input_feed, input_ids, attention_mask = preprocess_text(user_input)\n",
        "\n",
        "        try:\n",
        "            response_text = generate_text(input_feed, input_ids, attention_mask, max_new_tokens)\n",
        "            logger.info(f\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {psutil.virtual_memory().used / (1024 * 1024):.2f} MB\")\n",
        "            print(f\"ü§ñ ONNX: {response_text}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º —á–∞—Ç\n",
        "chat()"
      ],
      "metadata": {
        "id": "wm9iGf657QvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#--------------------------------------------------\n",
        "# üîπ –ê—Ä—Ö–∏–≤–∏—Ä—É–µ–º\n",
        "zip_name = \"DeepSeek-Qwen-splited-onnx.zip\"\n",
        "with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    for file in files:\n",
        "        zipf.write(file)\n",
        "logger.info(f\"üì¶ –ê—Ä—Ö–∏–≤ —Å–æ–∑–¥–∞–Ω: {zip_name}, —Ä–∞–∑–º–µ—Ä: {os.path.getsize(zip_name) / (1024 * 1024):.2f} MB\")\n",
        "\n",
        "#--------------------------------------------------\n",
        "# üîπ –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ Google Drive\n",
        "drive.mount('/content/drive')\n",
        "destination_path = f\"/content/drive/My Drive/{zip_name}\"\n",
        "!cp {zip_name} \"{destination_path}\"\n",
        "logger.info(f\"‚úÖ –ê—Ä—Ö–∏–≤ –∑–∞–≥—Ä—É–∂–µ–Ω –Ω–∞ Google Drive: {destination_path}\")\n"
      ],
      "metadata": {
        "id": "zxAmfEiF6doP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}